{"title":"Moment magnitude scale","summary":"The moment magnitude scale (MMS; denoted explicitly with Mw  or Mw, and generally implied with use of a single M for magnitude[1]) is a measure of an earthquake's magnitude (\"size\" or strength) based on its seismic moment. It was defined in a 1979 paper by Thomas C. Hanks and Hiroo Kanamori. Similar to the local magnitude scale (ML ) defined by Charles Francis Richter in 1935, it uses a logarithmic scale; small earthquakes have approximately the same magnitudes on both scales.","image":"842b1da2985931e3ed7ce31153e87242317114e1.svg","url":"Moment_magnitude_scale"}